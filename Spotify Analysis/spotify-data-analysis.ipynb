{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1e57e19f6a04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'max_rows'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'figure.figsize'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime as dt\n",
    "pd.set_option('max_rows',1000)\n",
    "sns.set(rc={'figure.figsize':(15,10)})\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from math import sqrt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df_year = pd.read_csv('data_by_year.csv')\n",
    "df_by_genres = pd.read_csv('data_by_genres.csv')\n",
    "df_w_genres = pd.read_csv('data_w_genres.csv')\n",
    "df_artist = pd.read_csv('data_by_artist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLANATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "df1['duration_ms'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['duration_ms'] = df1['duration_ms']/1000\n",
    "df1.rename({'duration_ms':'duration_in_seconds'},axis=1,inplace=True)\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Visualizations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(20,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(5,3,figsize=(20,25))\n",
    "sns.distplot(df1['valence'],ax=ax[0,0])\n",
    "sns.distplot(df1['year'],ax=ax[0,1])\n",
    "sns.distplot(df1['acousticness'],ax=ax[0,2])\n",
    "sns.distplot(df1['danceability'],ax=ax[1,0])\n",
    "sns.distplot(df1['duration_in_seconds'],ax=ax[1,1])\n",
    "sns.distplot(df1['energy'],ax=ax[1,2])\n",
    "#sns.distplot(df1['explicit'],ax=ax[2,0])\n",
    "sns.distplot(df1['instrumentalness'],ax=ax[2,1])\n",
    "sns.distplot(df1['key'],ax=ax[2,2])\n",
    "sns.distplot(df1['liveness'],ax=ax[3,0])\n",
    "sns.distplot(df1['loudness'],ax=ax[3,1])\n",
    "sns.distplot(df1['mode'],ax=ax[3,2])\n",
    "sns.distplot(df1['popularity'],ax=ax[4,0])\n",
    "sns.distplot(df1['speechiness'],ax=ax[4,1])\n",
    "sns.distplot(df1['tempo'],ax=ax[4,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(df1.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_pn = df1.groupby(\"name\")['popularity'].sum().sort_values(ascending=False)[:20]\n",
    "axis = sns.barplot(g_pn.index, g_pn,palette='rocket')\n",
    "axis.set_title('Top Tracks with Popularity')\n",
    "axis.set_ylabel('Popularity')\n",
    "axis.set_xlabel('Tracks')\n",
    "plt.xticks(rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_ap = df1.groupby(\"artists\")['popularity'].sum().sort_values(ascending=False)[:20]\n",
    "axis = sns.barplot(g_ap.index, g_ap,palette='magma_r')\n",
    "axis.set_title('Top Artists with Popularity')\n",
    "axis.set_ylabel('Popularity')\n",
    "axis.set_xlabel('Artists')\n",
    "plt.xticks(rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"acousticness\",\"danceability\",\"energy\",\"speechiness\",\"liveness\",\"valence\"]\n",
    "plt.figure(figsize=(15,10))\n",
    "for c in columns:\n",
    "    x = df1.groupby('year')[c].mean()\n",
    "    sns.lineplot(x.index,x,label=c)\n",
    "plt.title('Audio characteristics over year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Characteristics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_an = df1.groupby('artists')['name'].count().sort_values(ascending=False)[:20]\n",
    "axis = sns.barplot(g_an.index, g_an,palette='winter')\n",
    "axis.set_title('Top artists with tracks')\n",
    "axis.set_ylabel('Track count')\n",
    "axis.set_xlabel('Artists')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_an = df1.groupby('artists')['danceability'].mean().sort_values(ascending=False)[:20]\n",
    "axis = sns.barplot(g_an.index, g_an,palette='summer')\n",
    "axis.set_title('Top artists with danceability')\n",
    "axis.set_ylabel('danceability')\n",
    "axis.set_xlabel('Artists')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['year'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [1920,1960,2000,2020]\n",
    "df1['year_bins'] = pd.cut(df1['year'],bins,labels=['20s-60s','60s-2000','2000-2020'])\n",
    "df1['year_bins'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['year_bins'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_yp = df1.groupby('year_bins')['popularity'].mean().sort_values(ascending=False)[:20]\n",
    "axis = sns.barplot(g_yp.index, g_yp,palette='autumn_r')\n",
    "axis.set_title('popularity categories')\n",
    "axis.set_xlabel('Categories')\n",
    "axis.set_ylabel('popularity')\n",
    "#plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"valence\",\"popularity\",\"acousticness\",\"instrumentalness\",\"speechiness\",\"danceability\" ]\n",
    "sns.pairplot(df1[cols])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "d = df1[:10000]\n",
    "sns.scatterplot('tempo','popularity',data=d)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.barplot('explicit','popularity',data=df1,palette='rocket_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrds1 = g_ap.index.str.split(\"(\").str[0].value_counts().keys()\n",
    "wc1 = WordCloud(scale=5,max_words=1000,colormap=\"rainbow\",background_color=\"white\").generate(\" \".join(wrds1))\n",
    "plt.imshow(wc1,interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Artist Name for top 50 songs \",color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot('key','popularity',data=df1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML AND MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = LabelEncoder()\n",
    "df1['Artist_enc'] = enc.fit_transform(df1['artists'])\n",
    "df1['name_enc'] = enc.fit_transform(df1['name'])\n",
    "df1['year_bins'] = df1['year_bins'].map({'20s-60s':0,'60s-2000':1,'2000-2020':2})\n",
    "#print(df1['Artist_enc'].value_counts(),df1['name_enc'].value_counts())\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['valence', 'Artist_enc', 'danceability',\n",
    "       'duration_in_seconds', 'energy', 'explicit',\n",
    "       'key', 'liveness', 'loudness', 'mode', 'name_enc', 'tempo', 'year_bins']\n",
    "X = df1[cols]\n",
    "y = df1['popularity']\n",
    "X = X[:30000]\n",
    "y = y[:30000]\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42,shuffle=True)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models\n",
    "rf = RandomForestRegressor(bootstrap=True,criterion='mse',random_state=42,max_depth=35,\n",
    "                           n_estimators=2500,n_jobs=-1)\n",
    "xgb = XGBRegressor( booster='gbtree', colsample_bylevel=1,colsample_bynode=1, colsample_bytree=0.6, gamma=0,\n",
    "             importance_type='gain', learning_rate=0.01, max_delta_step=0,\n",
    "             max_depth=6, min_child_weight=4, n_estimators=4500,\n",
    "             n_jobs=4, nthread=None, objective='reg:linear',\n",
    "             reg_alpha=0.6, reg_lambda=0.6, scale_pos_weight=1, \n",
    "             silent=None, subsample=0.8, verbosity=1)\n",
    "gbr = GradientBoostingRegressor( learning_rate=0.01,) \n",
    "dtr = DecisionTreeRegressor(criterion='mse',random_state=42,max_depth=35,\n",
    "                           max_features='sqrt', min_samples_leaf=15, min_samples_split=10)\n",
    "abr = AdaBoostRegressor(dtr,learning_rate=0.01)\n",
    "cat =  CatBoostRegressor(learning_rate=0.1,eval_metric = 'RMSE',verbose=0)\n",
    "lgb = LGBMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(X_train,y_train)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test,xgb_pred)),mean_absolute_error(y_test,xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train,y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test,rf_pred)),mean_absolute_error(y_test,rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.fit(X_train,y_train)\n",
    "lgb_pred = lgb.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test,lgb_pred)),mean_absolute_error(y_test,lgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr.fit(X_train,y_train)\n",
    "dtr_pred = dtr.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test,dtr_pred)),mean_absolute_error(y_test,dtr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr.fit(X_train,y_train)\n",
    "gbr_pred = gbr.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test,gbr_pred)),mean_absolute_error(y_test,gbr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abr.fit(X_train,y_train)\n",
    "abr_pred = abr.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test,abr_pred)),mean_absolute_error(y_test,abr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.fit(X_train,y_train)\n",
    "cat_pred = cat.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test,cat_pred)),mean_absolute_error(y_test,cat_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Actual_Popularity':y_test,'Predicted_mean':np.round((cat_pred+xgb_pred+lgb_pred+rf_pred)/4,2)})\n",
    "output.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('output.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
